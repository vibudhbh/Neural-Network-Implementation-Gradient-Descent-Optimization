java GradientDescent mnist small_no_pool kaiming 100 svm 20 0.5 0.001 0.9 0 0.0 0.0 0 0.0
Log level set to INFO
[INFO   ] inputDropoutRate: 0.0, hiddenDropoutRate: 0.0
[INFO   ] reading image filename './datasets/train-images-idx3-ubyte' and label filename: './datasets/train-labels-idx1-ubyte
[INFO   ] read 60000 MNIST images.
[INFO   ] reading image filename './datasets/t10k-images-idx3-ubyte' and label filename: './datasets/t10k-labels-idx1-ubyte
[INFO   ] read 10000 MNIST images.
[INFO   ] Using an SVM loss function.
[INFO   ] Starting minibatch gradient descent!
[INFO   ] minibatch (100), mnist, svm, lr: 0.001, mu:0.9
[INFO   ] calculating initial error and accuracy
[INFO   ] bestError error accuracy testingError testingAccuracy
ITERATION  2.3025850929940423 2.3025850929940423   13.00000 2.3025850929940423    8.00000
[INFO   ] Learning rate: 9.75E-4
  1.2680237623448702 1.2680237623448702   58.00000 1.2605774126826272  58.00000
[INFO   ] Learning rate: 9.50625E-4
  0.5335232926012108 0.5335232926012108   85.00000 0.4292486303070674  80.00000
[INFO   ] Learning rate: 9.26859375E-4
  0.39064970341087873 0.39064970341087873   90.00000 0.3908182345088864  86.00000
[INFO   ] Learning rate: 9.036878906249999E-4
  0.2953635038599355 0.2953635038599355   92.00000 0.25272522976390654  93.00000
[INFO   ] Learning rate: 8.810956933593748E-4
  0.17121050823925352 0.17121050823925352   96.00000 0.1886234341301878  94.00000
[INFO   ] Learning rate: 8.590683010253904E-4
  0.16008904453199796 0.16008904453199796   97.00000 0.24484513490386395  91.00000
[INFO   ] Learning rate: 8.375915934997557E-4
  0.16008904453199796 0.1859614138106847   94.00000 0.17095540567994114  93.00000
[INFO   ] Learning rate: 8.166518036622618E-4
  0.16008904453199796 0.17330742015478337   97.00000 0.12561469421279825  94.00000
[INFO   ] Learning rate: 7.962355085707053E-4
  0.14856906591137847 0.14856906591137847   96.00000 0.12145848063500184  94.00000
[INFO   ] Learning rate: 7.763296208564376E-4
  0.14856906591137847 0.19232014504501468   97.00000 0.19011266563140364  96.00000
[INFO   ] Learning rate: 7.569213803350266E-4
  0.13635410745584348 0.13635410745584348   98.00000 0.10998524383327667  95.00000
[INFO   ] Learning rate: 7.37998345826651E-4
  0.13635410745584348 0.13645349438132295   98.00000 0.07147746913560912  98.00000
[INFO   ] Learning rate: 7.195483871809847E-4
  0.13635410745584348 0.14042065847819563   97.00000 0.12524723197948262  97.00000
[INFO   ] Learning rate: 7.015596775014601E-4
  0.07946774958175384 0.07946774958175384   98.00000 0.14406956957956718  96.00000
[INFO   ] Learning rate: 6.840206855639236E-4
  0.07946774958175384 0.15277304276080417   97.00000 0.11227941699880795  97.00000
[INFO   ] Learning rate: 6.669201684248255E-4
  0.07946774958175384 0.10888343786614295   96.00000 0.10888700668957188  97.00000
[INFO   ] Learning rate: 6.502471642142049E-4
  0.07946774958175384 0.17225399876599512   96.00000 0.14334796133740757  95.00000
[INFO   ] Learning rate: 6.339909851088498E-4
  0.07946774958175384 0.11695663141065628   98.00000 0.05203165283459246  97.00000
[INFO   ] Learning rate: 6.181412104811285E-4
  0.07946774958175384 0.11682577404437171   97.00000 0.09444581688492373  98.00000
[INFO   ] Learning rate: 6.026876802191003E-4
  0.07946774958175384 0.10311560240839861   98.00000 0.04654961955312633  99.00000
