java GradientDescent mnist lenet5 kaiming 100 softmax 25 0.0 0.001 0.5 1 0.3 0.1 1 0.1
Log level set to INFO
[INFO   ] inputDropoutRate: 0.3, hiddenDropoutRate: 0.1
[INFO   ] reading image filename './datasets/train-images-idx3-ubyte' and label filename: './datasets/train-labels-idx1-ubyte
[INFO   ] read 60000 MNIST images.
[INFO   ] reading image filename './datasets/t10k-images-idx3-ubyte' and label filename: './datasets/t10k-labels-idx1-ubyte
[INFO   ] read 10000 MNIST images.
[INFO   ] Using an SOFTMAX loss function.
[INFO   ] Starting minibatch gradient descent!
[INFO   ] minibatch (100), mnist, softmax, lr: 0.001, mu:0.5
[INFO   ] calculating initial error and accuracy
[INFO   ] bestError error accuracy testingError testingAccuracy
ITERATION  2.3025850929940423 2.3025850929940423   13.00000 2.3025850929940423    8.00000
[INFO   ] Learning rate: 9.75E-4
  0.1214370459799312 0.1214370459799312   97.00000 0.14165026321223875  96.00000
[INFO   ] Learning rate: 9.50625E-4
  0.08051104949370448 0.08051104949370448   99.00000 0.09702715076221619  97.00000
[INFO   ] Learning rate: 9.26859375E-4
  0.06755837305540607 0.06755837305540607   99.00000 0.07235200755990046  99.00000
[INFO   ] Learning rate: 9.036878906249999E-4
  0.06100334714167887 0.06100334714167887   99.00000 0.06409270525043569  99.00000
[INFO   ] Learning rate: 8.810956933593748E-4
  0.05852616436793314 0.05852616436793314   99.00000 0.06997769510955647  98.00000
[INFO   ] Learning rate: 8.590683010253904E-4
  0.05852616436793314 0.06371870392998275   99.00000 0.05689569710855077  97.00000
[INFO   ] Learning rate: 8.375915934997557E-4
  0.05852616436793314 0.06629473616738463   99.00000 0.07073493046704551  98.00000
[INFO   ] Learning rate: 8.166518036622618E-4
  0.05272472142225734 0.05272472142225734   99.00000 0.06910003990051712  98.00000
[INFO   ] Learning rate: 7.962355085707053E-4
  0.046853425220417536 0.046853425220417536   99.00000 0.059797584899561676  99.00000
[INFO   ] Learning rate: 7.763296208564376E-4
  0.046853425220417536 0.056890250850077886   99.00000 0.05356713741639096  98.00000
[INFO   ] Learning rate: 7.569213803350266E-4
  0.046853425220417536 0.048588597343722215   99.00000 0.04479329392728939  98.00000
[INFO   ] Learning rate: 7.37998345826651E-4
  0.046853425220417536 0.060783172908033416   99.00000 0.0574363676458362  98.00000
[INFO   ] Learning rate: 7.195483871809847E-4
  0.046853425220417536 0.05015293877986876   99.00000 0.056533322861883936  98.00000
[INFO   ] Learning rate: 7.015596775014601E-4
  0.046853425220417536 0.05694455560496173   99.00000 0.06525725222736446  97.00000
[INFO   ] Learning rate: 6.840206855639236E-4
  0.046853425220417536 0.05757712387021027   99.00000 0.06484714859556902  97.00000
[INFO   ] Learning rate: 6.669201684248255E-4
  0.046853425220417536 0.05179221159672529   99.00000 0.06995172621015125  97.00000
[INFO   ] Learning rate: 6.502471642142049E-4
  0.046853425220417536 0.05421514988177552   99.00000 0.07777056379417947  97.00000
[INFO   ] Learning rate: 6.339909851088498E-4
  0.046853425220417536 0.054299521863475066   99.00000 0.08774789734375137  97.00000
[INFO   ] Learning rate: 6.181412104811285E-4
  0.046853425220417536 0.05223999542561128   99.00000 0.05127130032705456  97.00000
[INFO   ] Learning rate: 6.026876802191003E-4
  0.046853425220417536 0.050722364639404056   99.00000 0.053285306867898695  97.00000
[INFO   ] Learning rate: 5.876204882136228E-4
  0.042879986197454756 0.042879986197454756   99.00000 0.051430684662267884  98.00000
[INFO   ] Learning rate: 5.729299760082822E-4
  0.042879986197454756 0.043753291909382534   99.00000 0.043507078607727366  99.00000
[INFO   ] Learning rate: 5.586067266080752E-4
  0.038236483206793535 0.038236483206793535   99.00000 0.042639511561434126  98.00000
[INFO   ] Learning rate: 5.446415584428732E-4
  0.038236483206793535 0.0407296867922893   99.00000 0.039438419538399556  97.00000
[INFO   ] Learning rate: 5.310255194818014E-4
  0.03627026414289426 0.03627026414289426   99.00000 0.040596463113780804  98.00000
